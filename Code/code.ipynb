{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eb8055a2",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bb8515bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import os\n",
    "import missingno\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cad1ec53",
   "metadata": {},
   "source": [
    "# Load and explore the dataset, visualizing the results of the exploration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "70a7e9e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "# 1. Load the dataset\n",
    "file_path = 'Production_Crops_Livestock_E_All_Data/Production_Crops_Livestock_E_All_Data_NOFLAG.csv'\n",
    "\n",
    "try:\n",
    "    # Load the data\n",
    "    df = pd.read_csv(file_path)\n",
    "    \n",
    "    # Display the first 5 rows\n",
    "    print(\"File loaded successfully!\")\n",
    "    #print(df.head())\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: The file was not found at {file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1a92269c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Filter for 'Production' (Element Code 5510) and unit 't' (tonnes)\n",
    "# This isolates the data representing the physical quantity produced.\n",
    "prod_df = df[(df['Element Code'] == 5510) & (df['Unit'] == 't')].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "df43ac1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. FILTER: Exclusion of Animal-derived Items (Proxy for 'plant production')\n",
    "# Define keywords to exclude (case-insensitive)\n",
    "animal_keywords = [\n",
    "    'Milk', 'Meat', 'Egg', 'Wool', 'Honey', 'Hides', \n",
    "    'Offal', 'Animals', 'Fats', 'Guts', 'Animal', 'Silkworm', \n",
    "    'Poultry', 'Carcass', 'Goat', 'Cattle', 'Sheep', 'Pig'\n",
    "]\n",
    "\n",
    "# Create an exclusion mask (True if it is an animal product)\n",
    "# The '|' joins the keywords with an OR logic.\n",
    "exclusion_mask = prod_df['Item'].str.contains('|'.join(animal_keywords), case=False, na=False)\n",
    "\n",
    "# Apply the filter: keep only items NOT in the exclusion mask (i.e., plant production)\n",
    "plant_prod_df = prod_df[~exclusion_mask].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "46be7343",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Identify the year columns\n",
    "# Finds all columns starting with 'Y' and representing an integer year between 1961 and 2023\n",
    "year_cols = [col for col in plant_prod_df.columns if col.startswith('Y') and col[1:].isdigit() and 1961 <= int(col[1:]) <= 2023]\n",
    "\n",
    "# Convert the year values to numeric (coercing errors to NaN)\n",
    "for col in year_cols:\n",
    "    plant_prod_df[col] = pd.to_numeric(plant_prod_df[col], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b72b47b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Calculate the total production (sum across all years) and group by Item\n",
    "# Calculate the total production for each record (Area/Item/Element combination)\n",
    "plant_prod_df['Total_Production'] = plant_prod_df[year_cols].sum(axis=1)\n",
    "\n",
    "# Group by Item and sum the grand total production\n",
    "total_production_by_plant_item = plant_prod_df.groupby('Item')['Total_Production'].sum().reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71e5a9ec",
   "metadata": {},
   "source": [
    "Select Top n plant-production"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "79e73dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 15 # <--- Top n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "660309f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Sort and select the Top n\n",
    "top_n_plant_items = total_production_by_plant_item.sort_values(by='Total_Production', ascending=False).head(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e5f1d3d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Format the result for printing\n",
    "top_n_items_formatted = top_n_plant_items.copy()\n",
    "# Convert total tonnes to Billions of Tonnes for readability\n",
    "top_n_items_formatted['Total_Production_Billion_Tonnes'] = top_n_items_formatted['Total_Production'] / 1e9\n",
    "top_n_items_formatted = top_n_items_formatted[['Item', 'Total_Production_Billion_Tonnes']].round(2)\n",
    "top_n_items_formatted.rename(columns={'Item': 'Plant Product', 'Total_Production_Billion_Tonnes': 'Total Production (Billion Tonnes)'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6b9fd549",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Top n Plant Products by Total Production (1961-2023) ---\n",
      "\n",
      "| Plant Product                  |   Total Production (Billion Tonnes) |\n",
      "|:-------------------------------|------------------------------------:|\n",
      "| Cereals, primary               |                              557.57 |\n",
      "| Sugar Crops Primary            |                              387.89 |\n",
      "| Sugar cane                     |                              314.85 |\n",
      "| Roots and Tubers, Total        |                              195.11 |\n",
      "| Vegetables Primary             |                              169.45 |\n",
      "| Maize (corn)                   |                              166.25 |\n",
      "| Rice                           |                              152.29 |\n",
      "| Wheat                          |                              149.45 |\n",
      "| Fruit Primary                  |                              148.27 |\n",
      "| Potatoes                       |                               88.12 |\n",
      "| Sugar beet                     |                               72.76 |\n",
      "| Cassava, fresh                 |                               55.15 |\n",
      "| Oilcrops, Cake Equivalent      |                               52.42 |\n",
      "| Other vegetables, fresh n.e.c. |                               50.27 |\n",
      "| Barley                         |                               40.05 |\n"
     ]
    }
   ],
   "source": [
    "# Print the result\n",
    "print(\"\\n--- Top n Plant Products by Total Production (1961-2023) ---\\n\")\n",
    "print(top_n_items_formatted.to_markdown(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6b49f9d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original rows: 78164\n",
      "Rows after filtering: 8698\n"
     ]
    }
   ],
   "source": [
    "top_n_Plant_Product = top_n_items_formatted['Plant Product'].to_list()\n",
    "\n",
    "# Filter the DataFrame, keeping only the rows where the 'Item' column\n",
    "# contains one of the values present in the 'valori_agricoli' list\n",
    "df_filtered = df[df['Item'].isin(top_n_Plant_Product)]\n",
    "\n",
    "# Check the result\n",
    "print(f\"Original rows: {len(df)}\")\n",
    "print(f\"Rows after filtering: {len(df_filtered)}\")\n",
    "#print(df_filtered.head())\n",
    "df = df_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0315baaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns remaining after cleanup:\n",
      "Index(['Area', 'Item', 'Element', 'Unit', 'Y1961', 'Y1962', 'Y1963', 'Y1964',\n",
      "       'Y1965', 'Y1966', 'Y1967', 'Y1968', 'Y1969', 'Y1970', 'Y1971', 'Y1972',\n",
      "       'Y1973', 'Y1974', 'Y1975', 'Y1976', 'Y1977', 'Y1978', 'Y1979', 'Y1980',\n",
      "       'Y1981', 'Y1982', 'Y1983', 'Y1984', 'Y1985', 'Y1986', 'Y1987', 'Y1988',\n",
      "       'Y1989', 'Y1990', 'Y1991', 'Y1992', 'Y1993', 'Y1994', 'Y1995', 'Y1996',\n",
      "       'Y1997', 'Y1998', 'Y1999', 'Y2000', 'Y2001', 'Y2002', 'Y2003', 'Y2004',\n",
      "       'Y2005', 'Y2006', 'Y2007', 'Y2008', 'Y2009', 'Y2010', 'Y2011', 'Y2012',\n",
      "       'Y2013', 'Y2014', 'Y2015', 'Y2016', 'Y2017', 'Y2018', 'Y2019', 'Y2020',\n",
      "       'Y2021', 'Y2022', 'Y2023'],\n",
      "      dtype='object')\n",
      "\n",
      "First 5 rows of the cleaned DataFrame:\n",
      "           Area          Item         Element   Unit     Y1961     Y1962  \\\n",
      "13  Afghanistan        Barley  Area harvested     ha  350000.0  350000.0   \n",
      "14  Afghanistan        Barley           Yield  kg/ha    1080.0    1080.0   \n",
      "15  Afghanistan        Barley      Production      t  378000.0  378000.0   \n",
      "61  Afghanistan  Maize (corn)  Area harvested     ha  500000.0  500000.0   \n",
      "62  Afghanistan  Maize (corn)           Yield  kg/ha    1400.0    1400.0   \n",
      "\n",
      "       Y1963     Y1964     Y1965     Y1966  ...     Y2014     Y2015     Y2016  \\\n",
      "13  350000.0  350000.0  350000.0  350000.0  ...  342472.0  282000.0  219208.0   \n",
      "14    1080.0    1085.7    1085.7    1071.4  ...    1521.3    1429.1    1377.0   \n",
      "15  378000.0  380000.0  380000.0  375000.0  ...  521000.0  403000.0  301856.0   \n",
      "61  500000.0  505000.0  500000.0  500000.0  ...  127000.0  147273.0  151900.0   \n",
      "62    1426.0    1425.7    1440.0    1440.0  ...    2488.2    2145.7    2051.7   \n",
      "\n",
      "       Y2017    Y2018     Y2019     Y2020     Y2021     Y2022     Y2023  \n",
      "13   68179.0  84147.0   84070.0   86099.0   40273.0   61952.0   80000.0  \n",
      "14    1393.3    674.8    1469.9    1483.8    1616.5    1528.4    1375.0  \n",
      "15   94995.0  56781.0  123576.0  127757.0   65102.0   94687.0  110000.0  \n",
      "61  134225.0  72433.0   94910.0  140498.0  139080.0  139000.0  127000.0  \n",
      "62    1295.7   1472.7    1945.7    1934.4    1900.4    2237.4    2858.3  \n",
      "\n",
      "[5 rows x 67 columns]\n"
     ]
    }
   ],
   "source": [
    "# 1. Define the list of columns to drop\n",
    "# We focus on removing redundant metadata columns (Codes, Flags, Domain info)\n",
    "COLUMNS_TO_DROP = [\n",
    "    'Area Code',\n",
    "    'Item Code',\n",
    "    'Element Code',\n",
    "    'Year Code',\n",
    "    'Flag',\n",
    "    'Flag Description',\n",
    "    'Symbol',\n",
    "    'Domain Code',\n",
    "    'Domain',\n",
    "    \n",
    "    #redundant\n",
    "    'Area Code', \n",
    "    'Area Code (M49)',\n",
    "    'Item Code', \n",
    "    'Item Code (CPC)',\n",
    "    'Element Code'\n",
    "    \n",
    "]\n",
    "\n",
    "# 2. Identify which columns from the list actually exist in the DataFrame (df_filtered)\n",
    "# This prevents the code from throwing an error if some columns are missing.\n",
    "existing_columns_to_drop = [col for col in COLUMNS_TO_DROP if col in df_filtered.columns]\n",
    "\n",
    "# 3. Drop the columns and create the clean DataFrame\n",
    "# axis=1 specifies that we are operating on columns\n",
    "df_clean = df_filtered.drop(columns=existing_columns_to_drop, axis=1)\n",
    "\n",
    "# 4. Check the result\n",
    "print(\"Columns remaining after cleanup:\")\n",
    "print(df_clean.columns)\n",
    "print(\"\\nFirst 5 rows of the cleaned DataFrame:\")\n",
    "print(df_clean.head())\n",
    "df = df_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "adfdec15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Area', 'Item', 'Element', 'Unit', 'Y1961', 'Y1962', 'Y1963', 'Y1964',\n",
       "       'Y1965', 'Y1966', 'Y1967', 'Y1968', 'Y1969', 'Y1970', 'Y1971', 'Y1972',\n",
       "       'Y1973', 'Y1974', 'Y1975', 'Y1976', 'Y1977', 'Y1978', 'Y1979', 'Y1980',\n",
       "       'Y1981', 'Y1982', 'Y1983', 'Y1984', 'Y1985', 'Y1986', 'Y1987', 'Y1988',\n",
       "       'Y1989', 'Y1990', 'Y1991', 'Y1992', 'Y1993', 'Y1994', 'Y1995', 'Y1996',\n",
       "       'Y1997', 'Y1998', 'Y1999', 'Y2000', 'Y2001', 'Y2002', 'Y2003', 'Y2004',\n",
       "       'Y2005', 'Y2006', 'Y2007', 'Y2008', 'Y2009', 'Y2010', 'Y2011', 'Y2012',\n",
       "       'Y2013', 'Y2014', 'Y2015', 'Y2016', 'Y2017', 'Y2018', 'Y2019', 'Y2020',\n",
       "       'Y2021', 'Y2022', 'Y2023'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "acfe1f39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame including Element and Unit:\n",
      "          Area    Item         Element  Year     Value\n",
      "0  Afghanistan  Barley  Area harvested  1961  350000.0\n",
      "1  Afghanistan  Barley           Yield  1961    1080.0\n",
      "2  Afghanistan  Barley      Production  1961  378000.0\n",
      "3  Afghanistan  Barley  Area harvested  1962  350000.0\n",
      "4  Afghanistan  Barley           Yield  1962    1080.0\n"
     ]
    }
   ],
   "source": [
    "# Assuming 'df' is your current wide DataFrame\n",
    "# If you have any other metadata columns (e.g., 'Flag', 'Symbol') in 'df', \n",
    "# add them to the 'fixed_id_vars' list below to keep them.\n",
    "\n",
    "fixed_id_vars = ['Area', 'Item', 'Element'\n",
    "                 #, 'Unit' remove Unit\n",
    "                 ] \n",
    "year_columns = [col for col in df.columns if col.startswith('Y')]\n",
    "\n",
    "df_with_metadata = (\n",
    "    df.melt(\n",
    "        id_vars=fixed_id_vars,\n",
    "        value_vars=year_columns,\n",
    "        var_name='Year',\n",
    "        value_name='Value'\n",
    "    )\n",
    "    .assign(Year=lambda x: x['Year'].str.replace('Y', '').astype(int))\n",
    "    #.query(\"Element == 'Production'\") # Still filtering rows to one variable\n",
    "    # NOTE: The .drop(columns=['Element', 'Unit']) step has been REMOVED.\n",
    "    .sort_values(by=['Area', 'Item', 'Year'])\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "print(\"DataFrame including Element and Unit:\")\n",
    "print(df_with_metadata.head())\n",
    "\n",
    "df = df_with_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "42240e1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "File 'analyzed_agricultural_data.csv' updated and saved to: processed data\\analyzed_agricultural_data.csv\n"
     ]
    }
   ],
   "source": [
    "# --- 1. Define Paths ---\n",
    "FOLDER_NAME = 'processed data'\n",
    "FILE_NAME = 'analyzed_agricultural_data.csv' # CSV Extension\n",
    "FULL_PATH = os.path.join(FOLDER_NAME, FILE_NAME)\n",
    "\n",
    "# --- 2. Create the Folder ---\n",
    "# Checks if the folder exists and creates it if it doesn't\n",
    "if not os.path.exists(FOLDER_NAME):\n",
    "    os.makedirs(FOLDER_NAME)\n",
    "    print(f\"The folder '{FOLDER_NAME}' has been created.\")\n",
    "\n",
    "# --- 3. Save the DataFrame as CSV ---\n",
    "# The to_csv() function OVERWRITES the existing file (the update mechanism).\n",
    "df.to_csv(\n",
    "    FULL_PATH, \n",
    "    index=False, # Do not save the Pandas row index\n",
    "    encoding='utf-8' # Standard encoding to support all characters\n",
    ")\n",
    "\n",
    "print(f\"\\nFile '{FILE_NAME}' updated and saved to: {FULL_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24c1dc70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory structure created: processed data\\processed_fao_data\n",
      "Filtering and saving files into the sub-folder...\n",
      " -> Saved: processed data\\processed_fao_data\\production_tonnes.csv\n",
      " -> Saved: processed data\\processed_fao_data\\area_harvested_ha.csv\n",
      " -> Saved: processed data\\processed_fao_data\\yield_kgha.csv\n",
      "\n",
      "Processing complete.\n"
     ]
    }
   ],
   "source": [
    "file_name = \"Production_Crops_Livestock_E_All_Data_NOFLAG.csv\"\n",
    "\n",
    "# DEFINITION OF FOLDER STRUCTURE\n",
    "# FOLDER_NAME = 'processed data'\n",
    "parent_folder =  FOLDER_NAME # Parent folder (Outer folder)\n",
    "# Sub-folder (Inner folder where files will actually go)\n",
    "sub_folder = \"processed_fao_data\"\n",
    "\n",
    "# Combine them to get the full path: \"FAO_Project_Output/processed_fao_data\"\n",
    "output_dir = os.path.join(parent_folder, sub_folder)\n",
    "\n",
    "# ==========================================\n",
    "# CREATE NESTED DIRECTORY STRUCTURE\n",
    "# ==========================================\n",
    "try:\n",
    "    # os.makedirs creates all intermediate directories needed\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    print(f\"Directory structure created: {output_dir}\")\n",
    "except OSError as e:\n",
    "    print(f\"Error creating directory {output_dir}: {e}\")\n",
    "    exit()\n",
    "\n",
    "# ==========================================\n",
    "# FILTER AND SAVE SEPARATE DATASETS\n",
    "# ==========================================\n",
    "filters = [\n",
    "    ('Production', 'production_tonnes.csv'),\n",
    "    ('Area harvested', 'area_harvested_ha.csv'),\n",
    "    ('Yield', 'yield_kgha.csv')\n",
    "]\n",
    "\n",
    "print(\"Filtering and saving files into the sub-folder...\")\n",
    "\n",
    "for element, filename in filters:\n",
    "    # Apply filter\n",
    "    df_filtered = df[df['Element'] == element].copy()\n",
    "    \n",
    "    # Create the full file path inside the nested folder\n",
    "    filepath = os.path.join(output_dir, filename)\n",
    "    \n",
    "    if not df_filtered.empty:\n",
    "        df_filtered.drop(columns=['Element']).to_csv(filepath, index=False)\n",
    "        print(f\" -> Saved: {filepath}\")\n",
    "    else:\n",
    "        print(f\" -> Warning: No data found for {element}).\")\n",
    "\n",
    "print(\"\\nProcessing complete.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
